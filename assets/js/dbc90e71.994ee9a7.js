"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[2107],{3905:(e,n,t)=>{t.d(n,{Zo:()=>d,kt:()=>h});var o=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,o,a=function(e,n){if(null==e)return{};var t,o,a={},r=Object.keys(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var l=o.createContext({}),p=function(e){var n=o.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},d=function(e){var n=p(e.components);return o.createElement(l.Provider,{value:n},e.children)},u="mdxType",c={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},m=o.forwardRef((function(e,n){var t=e.components,a=e.mdxType,r=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),u=p(t),m=a,h=u["".concat(l,".").concat(m)]||u[m]||c[m]||r;return t?o.createElement(h,i(i({ref:n},d),{},{components:t})):o.createElement(h,i({ref:n},d))}));function h(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var r=t.length,i=new Array(r);i[0]=m;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[u]="string"==typeof e?e:a,i[1]=s;for(var p=2;p<r;p++)i[p]=t[p];return o.createElement.apply(null,i)}return o.createElement.apply(null,t)}m.displayName="MDXCreateElement"},54634:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>c,frontMatter:()=>r,metadata:()=>s,toc:()=>p});var o=t(87462),a=(t(67294),t(3905));const r={},i="Building Q&A Assistant Using Mongo and OpenAI",s={unversionedId:"use_cases/items/question_the_docs",id:"use_cases/items/question_the_docs",title:"Building Q&A Assistant Using Mongo and OpenAI",description:"Introduction",source:"@site/content/use_cases/items/question_the_docs.md",sourceDirName:"use_cases/items",slug:"/use_cases/items/question_the_docs",permalink:"/docs/use_cases/items/question_the_docs",draft:!1,editUrl:"https://github.com/SuperDuperDB/superduperdb/tree/main/docs/content/use_cases/items/question_the_docs.md",tags:[],version:"current",frontMatter:{},sidebar:"useCasesSidebar",previous:{title:"Multimodal Search Using CLIP",permalink:"/docs/use_cases/items/multimodal_image_search_clip"},next:{title:"Creating a DB of image features in torchvision",permalink:"/docs/use_cases/items/resnet_features"}},l={},p=[{value:"Introduction",id:"introduction",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Connect to datastore",id:"connect-to-datastore",level:2},{value:"Load Dataset",id:"load-dataset",level:2},{value:"Create a Vector-Search Index",id:"create-a-vector-search-index",level:2},{value:"Create a Chat-Completion Component",id:"create-a-chat-completion-component",level:2},{value:"Ask Questions to Your Docs",id:"ask-questions-to-your-docs",level:2}],d={toc:p},u="wrapper";function c(e){let{components:n,...t}=e;return(0,a.kt)(u,(0,o.Z)({},d,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"building-qa-assistant-using-mongo-and-openai"},"Building Q&A Assistant Using Mongo and OpenAI"),(0,a.kt)("h2",{id:"introduction"},"Introduction"),(0,a.kt)("p",null,"This notebook is designed to demonstrate how to implement a document Question-and-Answer (Q&A) task using SuperDuperDB in conjunction with OpenAI and MongoDB. It provides a step-by-step guide and explanation of each component involved in the process."),(0,a.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,a.kt)("p",null,"Before diving into the implementation, ensure that you have the necessary libraries installed by running the following commands:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"!pip install superduperdb\n!pip install ipython openai==0.27.6\n")),(0,a.kt)("p",null,"Additionally, ensure that you have set your openai API key as an environment variable. You can uncomment the following code and add your API key:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"import os\n\n#os.environ['OPENAI_API_KEY'] = 'sk-...'\n\nif 'OPENAI_API_KEY' not in os.environ:\n    raise Exception('Environment variable \"OPENAI_API_KEY\" not set')\n")),(0,a.kt)("h2",{id:"connect-to-datastore"},"Connect to datastore"),(0,a.kt)("p",null,"First, we need to establish a connection to a MongoDB datastore via SuperDuperDB. You can configure the ",(0,a.kt)("inlineCode",{parentName:"p"},"MongoDB_URI")," based on your specific setup.\nHere are some examples of MongoDB URIs:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"For testing (default connection): ",(0,a.kt)("inlineCode",{parentName:"li"},"mongomock://test")),(0,a.kt)("li",{parentName:"ul"},"Local MongoDB instance: ",(0,a.kt)("inlineCode",{parentName:"li"},"mongodb://localhost:27017")),(0,a.kt)("li",{parentName:"ul"},"MongoDB with authentication: ",(0,a.kt)("inlineCode",{parentName:"li"},"mongodb://superduper:superduper@mongodb:27017/documents")),(0,a.kt)("li",{parentName:"ul"},"MongoDB Atlas: ",(0,a.kt)("inlineCode",{parentName:"li"},"mongodb+srv://<username>:<password>@<atlas_cluster>/<database>"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'from superduperdb import superduper\nfrom superduperdb.backends.mongodb import Collection\nimport os\n\nmongodb_uri = os.getenv("MONGODB_URI","mongomock://test")\ndb = superduper(mongodb_uri)\n\ncollection = Collection(\'questiondocs\')\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"db.metadata\n")),(0,a.kt)("h2",{id:"load-dataset"},"Load Dataset"),(0,a.kt)("p",null,"In this example we use the internal textual data from the ",(0,a.kt)("inlineCode",{parentName:"p"},"superduperdb")," project's API documentation. The goal is to create a chatbot that can provide information about the project. You can either load the data from your local project or use the provided data. "),(0,a.kt)("p",null,"If you have the SuperDuperDB project locally and want to load the latest version of the API, uncomment the following cell:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"# import glob\n\n# ROOT = '../docs/hr/content/docs/'\n\n# STRIDE = 3       # stride in numbers of lines\n# WINDOW = 25       # length of window in numbers of lines\n\n# files = sorted(glob.glob(f'{ROOT}/*.md') + glob.glob(f'{ROOT}/*.mdx'))\n\n# content = sum([open(file).read().split('\\n') for file in files], [])\n# chunks = ['\\n'.join(content[i: i + WINDOW]) for i in range(0, len(content), STRIDE)]\n")),(0,a.kt)("p",null,"Otherwise, you can load the data from an external source. The chunks of text contain code snippets and explanations, which will be used to build the document Q&A chatbot. "),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from IPython.display import *\n\nMarkdown(chunks[20])\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"!curl -O https://superduperdb-public.s3.eu-west-1.amazonaws.com/superduperdb_docs.json\n\nimport json\nfrom IPython.display import Markdown\n\nwith open('superduperdb_docs.json') as f:\n    chunks = json.load(f)\n")),(0,a.kt)("p",null,"You can see that the chunks of text contain bits of code, and explanations,\nwhich can become useful in building a document Q&A chatbot."),(0,a.kt)("p",null,"As usual we insert the data. The ",(0,a.kt)("inlineCode",{parentName:"p"},"Document")," wrapper allows ",(0,a.kt)("inlineCode",{parentName:"p"},"superduperdb")," to handle records with special data types such as images,\nvideo, and custom data-types."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb import Document\n\ndb.execute(collection.insert_many([Document({'txt': chunk}) for chunk in chunks]))\n")),(0,a.kt)("h2",{id:"create-a-vector-search-index"},"Create a Vector-Search Index"),(0,a.kt)("p",null,"To enable question-answering over your documents, we need to setup a standard ",(0,a.kt)("inlineCode",{parentName:"p"},"superduperdb")," vector-search index using ",(0,a.kt)("inlineCode",{parentName:"p"},"openai")," (although there are many options\nhere: ",(0,a.kt)("inlineCode",{parentName:"p"},"torch"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"sentence_transformers"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"transformers"),", ...)"),(0,a.kt)("p",null,"A ",(0,a.kt)("inlineCode",{parentName:"p"},"Model")," is a wrapper around a self-built or ecosystem model, such as ",(0,a.kt)("inlineCode",{parentName:"p"},"torch"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"transformers"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"openai"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb.ext.openai import OpenAIEmbedding\n\nmodel = OpenAIEmbedding(model='text-embedding-ada-002')\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"model.predict('This is a test', one=True)\n")),(0,a.kt)("p",null,"A ",(0,a.kt)("inlineCode",{parentName:"p"},"Listener"),' "deploys" a ',(0,a.kt)("inlineCode",{parentName:"p"},"Model"),' to "listen" to incoming data, and compute outputs, which are saved in the database, via ',(0,a.kt)("inlineCode",{parentName:"p"},"db"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb import Listener\n\nlistener = Listener(model=model, key='txt', select=collection.find())\n")),(0,a.kt)("p",null,"A ",(0,a.kt)("inlineCode",{parentName:"p"},"VectorIndex")," wraps a ",(0,a.kt)("inlineCode",{parentName:"p"},"Listener"),", making its outputs searchable."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb import VectorIndex\n\ndb.add(\n    VectorIndex(identifier='my-index', indexing_listener=listener)\n)\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"db.execute(collection.find_one())\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb.backends.mongodb import Collection\nfrom superduperdb import Document as D\nfrom IPython.display import *\n\nquery = 'Code snippet how to create a `VectorIndex` with a torchvision model'\n\nresult = db.execute(\n    collection\n        .like(D({'txt': query}), vector_index='my-index', n=5)\n        .find()\n)\n\ndisplay(Markdown('---'))\n\nfor r in result:\n    display(Markdown(r['txt']))\n    display(Markdown('---'))\n")),(0,a.kt)("h2",{id:"create-a-chat-completion-component"},"Create a Chat-Completion Component"),(0,a.kt)("p",null,"In this step, a chat-completion component is created and added to the system. This component is essential for the Q&A functionality:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb.ext.openai import OpenAIChatCompletion\n\nchat = OpenAIChatCompletion(\n    model='gpt-3.5-turbo',\n    prompt=(\n        'Use the following description and code-snippets aboout SuperDuperDB to answer this question about SuperDuperDB\\n'\n        'Do not use any other information you might have learned about other python packages\\n'\n        'Only base your answer on the code-snippets retrieved\\n'\n        '{context}\\n\\n'\n        'Here\\'s the question:\\n'\n    ),\n)\n\ndb.add(chat)\n\nprint(db.show('model'))\n")),(0,a.kt)("h2",{id:"ask-questions-to-your-docs"},"Ask Questions to Your Docs"),(0,a.kt)("p",null,"Finally, you can ask questions about the documents. You can target specific queries and use the power of MongoDB for vector-search and filtering rules. Here's an example of asking a question:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb import Document\nfrom IPython.display import Markdown\n\n# Define the search parameters\nsearch_term = 'Can you give me a code-snippet to set up a `VectorIndex`?'\nnum_results = 5\n\noutput, context = db.predict(\n    model_name='gpt-3.5-turbo',\n    input=search_term,\n    context_select=(\n        collection\n            .like(Document({'txt': search_term}), vector_index='my-index', n=num_results)\n            .find()\n    ),\n    context_key='txt',\n)\n\nMarkdown(output.content)\n")),(0,a.kt)("p",null,"Reset the demo"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"db.remove('vector_index', 'my-index', force=True)\ndb.remove('listener', 'text-embedding-ada-002/txt', force=True)\ndb.remove('model', 'text-embedding-ada-002', force=True)\n")))}c.isMDXComponent=!0}}]);