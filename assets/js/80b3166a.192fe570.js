"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[2159],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>h});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),p=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},d=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,s=e.originalType,l=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),c=p(a),m=r,h=c["".concat(l,".").concat(m)]||c[m]||u[m]||s;return a?n.createElement(h,o(o({ref:t},d),{},{components:a})):n.createElement(h,o({ref:t},d))}));function h(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var s=a.length,o=new Array(s);o[0]=m;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[c]="string"==typeof e?e:r,o[1]=i;for(var p=2;p<s;p++)o[p]=a[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},51969:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>i,toc:()=>p});var n=a(87462),r=(a(67294),a(3905));const s={},o="End-2-end example using SQL databases",i={unversionedId:"use_cases/items/sql-example",id:"use_cases/items/sql-example",title:"End-2-end example using SQL databases",description:"SuperDuperDB allows users to connect to a MongoDB database, or any one of a range of SQL databases, i.e. from this selection:",source:"@site/content/use_cases/items/sql-example.md",sourceDirName:"use_cases/items",slug:"/use_cases/items/sql-example",permalink:"/docs/use_cases/items/sql-example",draft:!1,editUrl:"https://github.com/SuperDuperDB/superduperdb/tree/main/docs/content/use_cases/items/sql-example.md",tags:[],version:"current",frontMatter:{},sidebar:"useCasesSidebar",previous:{title:"Sentiment analysis with transformers",permalink:"/docs/use_cases/items/sentiment_analysis_use_case"},next:{title:"Transfer Learning with Sentence Transformers and Scikit-Learn",permalink:"/docs/use_cases/items/transfer_learning"}},l={},p=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Connect to datastore",id:"connect-to-datastore",level:2},{value:"Load dataset",id:"load-dataset",level:2},{value:"Define schema",id:"define-schema",level:2},{value:"Add data to the datastore",id:"add-data-to-the-datastore",level:2},{value:"Build SuperDuperDB <code>Model</code> instances",id:"build-superduperdb-model-instances",level:2},{value:"Create a Vector-Search Index",id:"create-a-vector-search-index",level:2},{value:"Search Images Using Text",id:"search-images-using-text",level:2}],d={toc:p},c="wrapper";function u(e){let{components:t,...a}=e;return(0,r.kt)(c,(0,n.Z)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"end-2-end-example-using-sql-databases"},"End-2-end example using SQL databases"),(0,r.kt)("p",null,"SuperDuperDB allows users to connect to a MongoDB database, or any one of a range of SQL databases, i.e. from this selection:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"MongoDB"),(0,r.kt)("li",{parentName:"ul"},"PostgreSQL"),(0,r.kt)("li",{parentName:"ul"},"SQLite"),(0,r.kt)("li",{parentName:"ul"},"DuckDB"),(0,r.kt)("li",{parentName:"ul"},"BigQuery"),(0,r.kt)("li",{parentName:"ul"},"ClickHouse"),(0,r.kt)("li",{parentName:"ul"},"DataFusion"),(0,r.kt)("li",{parentName:"ul"},"Druid"),(0,r.kt)("li",{parentName:"ul"},"Impala"),(0,r.kt)("li",{parentName:"ul"},"MSSQL"),(0,r.kt)("li",{parentName:"ul"},"MySQL"),(0,r.kt)("li",{parentName:"ul"},"Oracle"),(0,r.kt)("li",{parentName:"ul"},"pandas"),(0,r.kt)("li",{parentName:"ul"},"Polars"),(0,r.kt)("li",{parentName:"ul"},"PySpark"),(0,r.kt)("li",{parentName:"ul"},"Snowflake"),(0,r.kt)("li",{parentName:"ul"},"Trino")),(0,r.kt)("p",null,"In this example we show case how to implement multimodal vector-search with DuckDB.\nThis is a simple extension of multimodal vector-search with MongoDB, which is\njust slightly easier to set-up (see ",(0,r.kt)("a",{parentName:"p",href:"https://docs.superduperdb.com/docs/use_cases/items/multimodal_image_search_clip"},"here"),").\nEverything we do here applies equally to any of the above supported SQL databases, as well as to tabular data formats on disk, such as ",(0,r.kt)("inlineCode",{parentName:"p"},"pandas"),"."),(0,r.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,r.kt)("p",null,"Before working on this use-case, make sure that you've installed the software requirements:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"!pip install superduperdb[demo]\n")),(0,r.kt)("h2",{id:"connect-to-datastore"},"Connect to datastore"),(0,r.kt)("p",null,"The first step in any ",(0,r.kt)("inlineCode",{parentName:"p"},"superduperdb")," workflow is to connect to your datastore.\nIn order to connect to a different datastore, add a different ",(0,r.kt)("inlineCode",{parentName:"p"},"URI"),", e.g. ",(0,r.kt)("inlineCode",{parentName:"p"},"postgres://..."),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import os\nfrom superduperdb import superduper\n\nos.makedirs('.superduperdb', exist_ok=True)\ndb = superduper('duckdb://.superduperdb/test.ddb')\n")),(0,r.kt)("h2",{id:"load-dataset"},"Load dataset"),(0,r.kt)("p",null,"Now, Once connected, add some data to the datastore:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"!curl -O https://superduperdb-public.s3.eu-west-1.amazonaws.com/coco_sample.zip\n!curl -O https://superduperdb-public.s3.eu-west-1.amazonaws.com/captions_tiny.json\n!unzip coco_sample.zip\n!mkdir -p data/coco\n!mv images_small data/coco/images\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import json\nimport pandas\nimport PIL.Image\n\nwith open(captions_tiny.json') as f:\n    data = json.load(f)[:500]\n    \ndata = pandas.DataFrame([\n    {\n        'image': r['image']['_content']['path'], \n         'captions': r['captions']\n    } for r in data   \n])\ndata['id'] = pandas.Series(data.index).apply(str)\nimages_df = data[['id', 'image']]\n\nimages_df['image'] = images_df['image'].apply(PIL.Image.open)\ncaptions_df = data[['id', 'captions']].explode('captions')\n")),(0,r.kt)("h2",{id:"define-schema"},"Define schema"),(0,r.kt)("p",null,"This use-case requires a table with images, and a table with text.\nSuperDuperDB extends standard SQL functionality, by allowing developers to define\ntheir own data-types via the ",(0,r.kt)("inlineCode",{parentName:"p"},"Encoder")," abstraction."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb.backends.ibis.query import Table\nfrom superduperdb.backends.ibis.field_types import dtype\nfrom superduperdb.ext.pillow import pil_image\nfrom superduperdb import Schema\n\ncaptions = Table(\n    'captions', \n    primary_id='id',\n    schema=Schema(\n        'captions-schema',\n        fields={'id': dtype(str), 'captions': dtype(str)},\n    )\n)\n\nimages = Table(\n    'images', \n    primary_id='id',\n    schema=Schema(\n        'images-schema',\n        fields={'id': dtype(str), 'image': pil_image},\n    )\n)\n\ndb.add(captions)\ndb.add(images)\n")),(0,r.kt)("h2",{id:"add-data-to-the-datastore"},"Add data to the datastore"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"_ = db.execute(images.insert(images_df))\n_ = db.execute(captions.insert(captions_df))\n")),(0,r.kt)("h2",{id:"build-superduperdb-model-instances"},"Build SuperDuperDB ",(0,r.kt)("inlineCode",{parentName:"h2"},"Model")," instances"),(0,r.kt)("p",null,"This use-case uses the ",(0,r.kt)("inlineCode",{parentName:"p"},"superduperdb.ext.torch")," extension.\nBoth models used, output ",(0,r.kt)("inlineCode",{parentName:"p"},"torch")," tensors, which are encoded with ",(0,r.kt)("inlineCode",{parentName:"p"},"tensor"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import clip\nimport torch\nfrom superduperdb.ext.torch import TorchModel, tensor\n\n# Load the CLIP model\nmodel, preprocess = clip.load(\"RN50\", device='cpu')\n\n# Define a tensor type\nt = tensor(torch.float, shape=(1024,))\n\n# Create a TorchModel for text encoding\ntext_model = TorchModel(\n    identifier='clip_text',\n    object=model,\n    preprocess=lambda x: clip.tokenize(x)[0],\n    encoder=t,\n    forward_method='encode_text',    \n)\n\n# Create a TorchModel for visual encoding\nvisual_model = TorchModel(\n    identifier='clip_image',\n    object=model.visual,    \n    preprocess=preprocess,\n    encoder=t,\n)\n")),(0,r.kt)("h2",{id:"create-a-vector-search-index"},"Create a Vector-Search Index"),(0,r.kt)("p",null,"Let's define a mult-modal search index on the basis of the models imported above.\nThe ",(0,r.kt)("inlineCode",{parentName:"p"},"visual_model")," is applied to the images, to make the ",(0,r.kt)("inlineCode",{parentName:"p"},"images")," table searchable."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb import VectorIndex, Listener\n\ndb.add(\n    VectorIndex(\n        'my-index',\n        indexing_listener=Listener(\n            model=visual_model,\n            key='image',\n            select=images,\n        ),\n        compatible_listener=Listener(\n            model=text_model,\n            key='captions',\n            active=False,\n            select=None,\n        )\n    )\n)\n")),(0,r.kt)("h2",{id:"search-images-using-text"},"Search Images Using Text"),(0,r.kt)("p",null,"Now we can demonstrate searching for images using text queries:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from superduperdb import Document\n\nres = db.execute(\n    images\n        .like(Document({'captions': 'dog catches frisbee'}), vector_index='my-index', n=10)\n        .limit(10)\n)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"res[3]['image'].x\n")))}u.isMDXComponent=!0}}]);