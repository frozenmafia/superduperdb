"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[5175],{3905:(e,n,t)=>{t.d(n,{Zo:()=>d,kt:()=>h});var r=t(67294);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function a(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,r,i=function(e,n){if(null==e)return{};var t,r,i={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var l=r.createContext({}),c=function(e){var n=r.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):a(a({},n),e)),t},d=function(e){var n=c(e.components);return r.createElement(l.Provider,{value:n},e.children)},u="mdxType",p={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},m=r.forwardRef((function(e,n){var t=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),u=c(t),m=i,h=u["".concat(l,".").concat(m)]||u[m]||p[m]||o;return t?r.createElement(h,a(a({ref:n},d),{},{components:t})):r.createElement(h,a({ref:n},d))}));function h(e,n){var t=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var o=t.length,a=new Array(o);a[0]=m;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[u]="string"==typeof e?e:i,a[1]=s;for(var c=2;c<o;c++)a[c]=t[c];return r.createElement.apply(null,a)}return r.createElement.apply(null,t)}m.displayName="MDXCreateElement"},18562:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var r=t(87462),i=(t(67294),t(3905));const o={},a="Training and Maintaining MNIST Predictions with SuperDuperDB",s={unversionedId:"use_cases/items/mnist_torch",id:"use_cases/items/mnist_torch",title:"Training and Maintaining MNIST Predictions with SuperDuperDB",description:"Introduction",source:"@site/content/use_cases/items/mnist_torch.md",sourceDirName:"use_cases/items",slug:"/use_cases/items/mnist_torch",permalink:"/docs/use_cases/items/mnist_torch",draft:!1,editUrl:"https://github.com/SuperDuperDB/superduperdb/tree/main/docs/content/use_cases/items/mnist_torch.md",tags:[],version:"current",frontMatter:{},sidebar:"useCasesSidebar",previous:{title:"Chunked vector-search using multiple inputs per document",permalink:"/docs/use_cases/items/chunked_vector_search"},next:{title:"Multimodal Search Using CLIP",permalink:"/docs/use_cases/items/multimodal_image_search_clip"}},l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Connect to datastore",id:"connect-to-datastore",level:2},{value:"Load Dataset",id:"load-dataset",level:2},{value:"Build Model",id:"build-model",level:2},{value:"Train Model",id:"train-model",level:2},{value:"Monitoring Training Efficiency",id:"monitoring-training-efficiency",level:2},{value:"On-the-fly Predictions",id:"on-the-fly-predictions",level:2},{value:"Verification",id:"verification",level:2}],d={toc:c},u="wrapper";function p(e){let{components:n,...t}=e;return(0,i.kt)(u,(0,r.Z)({},d,t,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"training-and-maintaining-mnist-predictions-with-superduperdb"},"Training and Maintaining MNIST Predictions with SuperDuperDB"),(0,i.kt)("h2",{id:"introduction"},"Introduction"),(0,i.kt)("p",null,"This notebook outlines the process of implementing a classic machine learning classification task - MNIST handwritten digit recognition, using a convolutional neural network. However, we introduce a unique twist by performing the task in a database using SuperDuperDB."),(0,i.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,i.kt)("p",null,"Before diving into the implementation, ensure that you have the necessary libraries installed by running the following commands:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"!pip install superduperdb\n!pip install torch torchvision matplotlib\n")),(0,i.kt)("h2",{id:"connect-to-datastore"},"Connect to datastore"),(0,i.kt)("p",null,"First, we need to establish a connection to a MongoDB datastore via SuperDuperDB. You can configure the ",(0,i.kt)("inlineCode",{parentName:"p"},"MongoDB_URI")," based on your specific setup.\nHere are some examples of MongoDB URIs:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"For testing (default connection): ",(0,i.kt)("inlineCode",{parentName:"li"},"mongomock://test")),(0,i.kt)("li",{parentName:"ul"},"Local MongoDB instance: ",(0,i.kt)("inlineCode",{parentName:"li"},"mongodb://localhost:27017")),(0,i.kt)("li",{parentName:"ul"},"MongoDB with authentication: ",(0,i.kt)("inlineCode",{parentName:"li"},"mongodb://superduper:superduper@mongodb:27017/documents")),(0,i.kt)("li",{parentName:"ul"},"MongoDB Atlas: ",(0,i.kt)("inlineCode",{parentName:"li"},"mongodb+srv://<username>:<password>@<atlas_cluster>/<database>"))),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from superduperdb import superduper\nfrom superduperdb.backends.mongodb import Collection\nimport os\n\nmongodb_uri = os.getenv("MONGODB_URI","mongomock://test")\ndb = superduper(mongodb_uri)\n\n# Create a collection for MNIST\nmnist_collection = Collection(\'mnist\')\n')),(0,i.kt)("h2",{id:"load-dataset"},"Load Dataset"),(0,i.kt)("p",null,'After connecting to MongoDB, we add the MNIST dataset. SuperDuperDB excels at handling "difficult" data types, and we achieve this using an ',(0,i.kt)("inlineCode",{parentName:"p"},"Encoder"),", which works in tandem with the ",(0,i.kt)("inlineCode",{parentName:"p"},"Document")," wrappers. Together, they enable Python dictionaries containing non-JSONable or bytes objects to be inserted into the underlying data infrastructure. "),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"import torchvision\nfrom superduperdb.ext.pillow import pil_image\nfrom superduperdb import Document\nfrom superduperdb.backends.mongodb import Collection\n\nimport random\n\n# Load MNIST images as Python objects using the Python Imaging Library.\nmnist_data = list(torchvision.datasets.MNIST(root='./data', download=True))\ndocument_list = [Document({'img': pil_image(x[0]), 'class': x[1]}) for x in mnist_data]\n\n# Shuffle the data and select a subset of 1000 documents\nrandom.shuffle(document_list)\ndata = document_list[:1000]\n\n# Insert the selected data into the mnist_collection\ndb.execute(\n    mnist_collection.insert_many(data[:-100]),  # Insert all but the last 100 documents\n    encoders=(pil_image,) # Encode images using the Pillow library.\n)\n")),(0,i.kt)("p",null,"Now that the images and their classes are inserted into the database, we can query the data in its original format. Particularly, we can use the ",(0,i.kt)("inlineCode",{parentName:"p"},"PIL.Image")," instances to inspect the data."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"# Get and display one of the images\nr = db.execute(mnist_collection.find_one())\nr.unpack()['img']\n")),(0,i.kt)("h2",{id:"build-model"},"Build Model"),(0,i.kt)("p",null,"Next, we create our machine learning model. SuperDuperDB supports various frameworks out of the box, and in this case, we are using PyTorch, which is well-suited for computer vision tasks. In this example, we combine torch with torchvision."),(0,i.kt)("p",null,"We create ",(0,i.kt)("inlineCode",{parentName:"p"},"postprocess")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"preprocess")," functions to handle the communication with the SuperDuperDB ",(0,i.kt)("inlineCode",{parentName:"p"},"Datalayer"),", and then wrap model, preprocessing and postprocessing to create a native SuperDuperDB handler."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"import torch\n\nclass LeNet5(torch.nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.layer1 = torch.nn.Sequential(\n            torch.nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n            torch.nn.BatchNorm2d(6),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n        self.layer2 = torch.nn.Sequential(\n            torch.nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n            torch.nn.BatchNorm2d(16),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n        self.fc = torch.nn.Linear(400, 120)\n        self.relu = torch.nn.ReLU()\n        self.fc1 = torch.nn.Linear(120, 84)\n        self.relu1 = torch.nn.ReLU()\n        self.fc2 = torch.nn.Linear(84, num_classes)\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc(out)\n        out = self.relu(out)\n        out = self.fc1(out)\n        out = self.relu1(out)\n        out = self.fc2(out)\n        return out\n\n    \ndef postprocess(x):\n    return int(x.topk(1)[1].item())\n\n\ndef preprocess(x):\n    return torchvision.transforms.Compose([\n        torchvision.transforms.Resize((32, 32)),\n        torchvision.transforms.ToTensor(),\n        torchvision.transforms.Normalize(mean=(0.1307,), std=(0.3081,))]\n    )(x)\n\n\n# Create and insert a SuperDuperDB model into the database\nmodel = superduper(LeNet5(10), preprocess=preprocess, postprocess=postprocess, preferred_devices=('cpu',))\ndb.add(model)\n")),(0,i.kt)("h2",{id:"train-model"},"Train Model"),(0,i.kt)("p",null,'Now we are ready to "train" or "fit" the model. Trainable models in SuperDuperDB come with a sklearn-like ',(0,i.kt)("inlineCode",{parentName:"p"},".fit")," method. "),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"from torch.nn.functional import cross_entropy\n\nfrom superduperdb import Metric\nfrom superduperdb import Dataset\nfrom superduperdb.ext.torch.model import TorchTrainerConfiguration\n\n# Fit the model to the training data\njob = model.fit(\n    X='img', # Feature matrix used as input data \n    y='class', # Target variable for training\n    db=db, # Database used for data retrieval\n    select=mnist_collection.find(), # Select the dataset\n    configuration=TorchTrainerConfiguration(\n        identifier='my_configuration',\n        objective=cross_entropy,\n        loader_kwargs={'batch_size': 10},\n        max_iterations=10,\n        validation_interval=5,\n    ),\n    metrics=[Metric(identifier='acc', object=lambda x, y: sum([xx == yy for xx, yy in zip(x, y)]) / len(x))],\n    validation_sets=[\n        Dataset(\n            identifier='my_valid',\n            select=Collection('mnist').find({'_fold': 'valid'}),\n        )\n    ],\n    distributed=False,\n)\n")),(0,i.kt)("h2",{id:"monitoring-training-efficiency"},"Monitoring Training Efficiency"),(0,i.kt)("p",null,"You can monitor the training efficiency with visualization tools like Matplotlib:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"from matplotlib import pyplot as plt\n\n# Load the model from the database\nmodel = db.load('model', model.identifier)\n\n# Plot the accuracy values\nplt.plot(model.metric_values['my_valid/acc'])\nplt.show()\n")),(0,i.kt)("h2",{id:"on-the-fly-predictions"},"On-the-fly Predictions"),(0,i.kt)("p",null,"Once the model is trained, you can use it to continuously predict on new data as it arrives. This is set up by enabling a ",(0,i.kt)("inlineCode",{parentName:"p"},"listener")," for the database (without loading all the data client-side). The listen toggle activates the model to make predictions on incoming data changes."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"model.predict(\n    X='img', # Input feature  \n    db=db,  # Database used for data retrieval\n    select=mnist_collection.find(), # Select the dataset\n    listen=True, # Continuous predictions on incoming data \n    max_chunk_size=100, # Number of predictions to return at once\n)\n")),(0,i.kt)("p",null,"We can see that predictions are available in ",(0,i.kt)("inlineCode",{parentName:"p"},"_outputs.img.lenet5"),"."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"r = db.execute(mnist_collection.find_one({'_fold': 'valid'}))\nr.unpack()\n")),(0,i.kt)("h2",{id:"verification"},"Verification"),(0,i.kt)("p",null,'The models "activated" can be seen here:'),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"db.show('listener')\n")),(0,i.kt)("p",null,"We can verify that the model is activated, by inserting the rest of the data:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"for r in data[-100:]:\n    r['update'] = True\n\ndb.execute(mnist_collection.insert_many(data[-100:]))\n")),(0,i.kt)("p",null,"You can see that the inserted data, are now also populated with predictions:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"db.execute(mnist_collection.find_one({'update': True}))['_outputs']\n")))}p.isMDXComponent=!0}}]);